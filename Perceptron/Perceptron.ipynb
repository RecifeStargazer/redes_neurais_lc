{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCGB7DJ9An+YvIru2oTWnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/redes_neurais_lc/blob/main/Perceptron/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yyyz9kf3US8",
        "outputId": "06a29249-3c13-4c2a-ffb4-355a7d892326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/valmirf/redes_neurais_lc.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'redes_neurais_lc'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV4FHtiCf-HP"
      },
      "source": [
        "# **C√≥digo da Rede Neural Perceptron**\n",
        "\n",
        "Abaixo √© apresentado um c√≥digo do perceptron. Prestem aten√ß√£o nas equa√ß√µes e etapas de treinamento.\n",
        "\n",
        "\n",
        "##Somat√≥rio:\n",
        "\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "##Atualiza√ß√£o dos Pesos:\n",
        "\n",
        "Œîùë§_ùëñ=ùúÇ(ùë°‚àíùëú)ùë•_ùëñ\n",
        "\n",
        "ùë§_(ùëñ+1)=ùë§_ùëñ+Œîùë§_ùëñ\n",
        "\n",
        "## Par√¢metros: \n",
        "ùëõ = N√∫mero de exemplos\n",
        "\n",
        "ùë•_ùëñ= Vetor de caracter√≠sticas do exemplo ùëñ\n",
        "\n",
        "ùë§_ùëñ= Peso da conex√£o ùëñ\n",
        "\n",
        "ùëá = Limiar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EHLTqwin5It"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron(object):\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=0.2, nIterations=100, learning_rate=0.01):\n",
        "        self.nIterations = nIterations\n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.zeros(no_of_inputs)\n",
        "           \n",
        "    def predict(self, inputs):\n",
        "        #.dot = produto de dois arrays (somat√≥rio entre entrada e peso)\n",
        "        summation = np.dot(inputs, self.weights)\n",
        "        #print(summation)\n",
        "        if summation >= self.threshold:\n",
        "          activation = 1\n",
        "        else:\n",
        "          activation = 0            \n",
        "        return activation\n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "        for _ in range(self.nIterations):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                #delta = w_i + n*(t-o)*x\n",
        "                delta = self.learning_rate * (label - prediction) * inputs\n",
        "                #w_(i+1) = w_i + delta \n",
        "                self.weights += delta\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCCCgVXChwpm"
      },
      "source": [
        "#Exemplo dado em Sala de Aula:\n",
        "\n",
        "##Operador AND\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9zGKKaqf6I5",
        "outputId": "b2530ff5-5efb-47a1-f3c5-23ff7f0f138b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_inputs = []\n",
        "training_inputs.append(np.array([1, 1]))\n",
        "training_inputs.append(np.array([1, 0]))\n",
        "training_inputs.append(np.array([0, 1]))\n",
        "training_inputs.append(np.array([0, 0]))\n",
        "\n",
        "labels = np.array([1, 0, 0, 0])\n",
        "\n",
        "perceptron = Perceptron(2)\n",
        "perceptron.train(training_inputs, labels)\n",
        "\n",
        "inputs = np.array([1, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 1\n",
        "\n",
        "inputs = np.array([0, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhoPmRkRkVH2"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "#Exerc√≠cios:\n",
        "\n",
        "1. Altere o c√≥digo abaixo para o operador XOR. Deixe os par√¢metros no padr√£o. Qual o resultado para [1,1] e [0,1]? \n",
        "\n",
        "2. Porque o resultado deu errado na quest√£o anterior?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaCPZN-NmH5z",
        "outputId": "191e8c47-4551-4e4e-8c2a-ddb2d95a834d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_inputs = []\n",
        "training_inputs.append(np.array([1, 1]))\n",
        "training_inputs.append(np.array([1, 0]))\n",
        "training_inputs.append(np.array([0, 1]))\n",
        "training_inputs.append(np.array([0, 0]))\n",
        "\n",
        "labels = np.array([1, 0, 0, 0])\n",
        "\n",
        "perceptron = Perceptron(2)\n",
        "perceptron.train(training_inputs, labels)\n",
        "\n",
        "inputs = np.array([1, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 1\n",
        "\n",
        "inputs = np.array([0, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KZ19-RLkW4w"
      },
      "source": [
        "3. Atualize a fun√ß√£o de ativa√ß√£o do perceptron para a fun√ß√£o sigm√≥ide. \n",
        "\n",
        "OBS: Essa atualiza√ß√£o far√° o Percetron se transformar na Rede Neural Adaline, que utiliza uma fun√ß√£o de ativa√ß√£o cont√≠nua ao inv√©s de uma fun√ß√£o limiar bin√°ria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M4NMoDikbA5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron_to_Adaline(object):\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=0.2, nIterations=100, learning_rate=0.01):\n",
        "        self.nIterations = nIterations\n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.zeros(no_of_inputs)\n",
        "           \n",
        "    def predict(self, inputs):\n",
        "        #.dot = produto de dois arrays (somat√≥rio entre entrada e peso)\n",
        "        summation = np.dot(inputs, self.weights)\n",
        "        print(summation)\n",
        "        if summation >= self.threshold:\n",
        "          activation = 1\n",
        "        else:\n",
        "          activation = 0            \n",
        "        return activation\n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "        for _ in range(self.nIterations):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                #delta = w_i + n*(t-o)*x\n",
        "                delta = self.learning_rate * (label - prediction) * inputs\n",
        "                #w_(i+1) = w_i + delta \n",
        "                self.weights += delta\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0fiUIJIkYcQ"
      },
      "source": [
        "4. Agora, altere o c√≥digo para que execute a base de dados Diabetes como Entrada. Avalie os hiperpar√¢metros abaixo nas redes Perceptron e Adaline, e diga a taxa de acerto no conjunto de testes pra cada configura√ß√£o.\n",
        "a) Taxa de Aprendizado = 0.001 e Limiar= 0.2\n",
        "b) Taxa de Aprendizado = 0.1 e Limiar= 0.2\n",
        "c) Taxa de Aprendizado = 0.001 e Limiar= 0.5\n",
        "d) Taxa de Aprendizado = 0.1 e Limiar= 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq9HZFUYkc5D",
        "outputId": "7efe5443-735a-4811-8b6a-b6cb94c6f214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "# Neste c√≥digo vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
        "def load_data():\n",
        "    url = 'redes_neurais_lc/Perceptron/diabetes.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    #remove a ultima coluna (dados)\n",
        "    data = df[df.columns[:-1]]\n",
        "    #normaliza os dados\n",
        "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
        "    #retorna a √∫ltima coluna (r√≥tulos)\n",
        "    labels = df[df.columns[-1]]\n",
        "    #separa em conjunto de treinamento e teste com seus respectivos r√≥tulos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "#chama fun√ß√£o que carrega base de dados\n",
        "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
        "\n",
        "#Treina Perceptron\n",
        "perceptron = Perceptron(8)\n",
        "perceptron.train(training_inputs.values, training_labels.values)\n",
        "\n",
        "#Avalia primeiro elemento do conjunto de testes\n",
        "p = perceptron.predict(test_inputs.iloc[0].values) \n",
        "print('predicted: ', p)\n",
        "print('label: ', test_labels.iloc[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9f1d01a69142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#chama fun√ß√£o que carrega base de dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#Treina Perceptron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-9f1d01a69142>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'redes_neurais_lc/Perceptron/diabetes.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#remove a ultima coluna (dados)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'redes_neurais_lc/Perceptron/diabetes.csv'"
          ]
        }
      ]
    }
  ]
}